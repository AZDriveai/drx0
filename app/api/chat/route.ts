import { streamText } from 'ai'
import { createOpenAI } from '@ai-sdk/openai'
import { generateObject } from 'ai'
import { z } from 'zod'

export const maxDuration = 60

// Ø¥Ø¹Ø¯Ø§Ø¯ DeepSeek Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
const deepseek = createOpenAI({
  baseURL: 'https://api.deepseek.com',
  apiKey: process.env.DEEPSEEK_API_KEY,
})

// Ù†Ø¸Ø§Ù… Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø°ÙƒÙŠØ©
class ConversationMemory {
  constructor() {
    this.context = {
      userProfile: {},
      conversationHistory: [],
      expertise: {},
      preferences: {}
    }
  }

  analyzeUser(messages) {
    // ØªØ­Ù„ÙŠÙ„ Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ£Ø³Ù„ÙˆØ¨Ù‡
    const userPatterns = {
      technical: messages.filter(m => /ÙƒÙˆØ¯|Ø¨Ø±Ù…Ø¬Ø©|ØªÙ‚Ù†ÙŠ|API/i.test(m.content)).length,
      creative: messages.filter(m => /Ø¥Ø¨Ø¯Ø§Ø¹|ÙÙƒØ±Ø©|ØªØµÙ…ÙŠÙ…|Ù…Ø¨ØªÙƒØ±/i.test(m.content)).length,
      analytical: messages.filter(m => /ØªØ­Ù„ÙŠÙ„|Ø¥Ø­ØµØ§Ø¦ÙŠØ©|Ø¨ÙŠØ§Ù†Ø§Øª|Ø¯Ø±Ø§Ø³Ø©/i.test(m.content)).length,
      conversational: messages.filter(m => /ÙƒÙŠÙ|Ù…Ø§Ø°Ø§|Ù„Ù…Ø§Ø°Ø§|Ø£Ø±ÙŠØ¯/i.test(m.content)).length
    }

    const dominantStyle = Object.entries(userPatterns)
      .sort(([,a], [,b]) => b - a)[0][0]

    this.context.userProfile = {
      dominantStyle,
      patterns: userPatterns,
      complexity: this.calculateComplexity(messages),
      language: this.detectLanguage(messages)
    }

    return this.context.userProfile
  }

  calculateComplexity(messages) {
    const avgLength = messages.reduce((sum, m) => sum + m.content.length, 0) / messages.length
    if (avgLength > 200) return 'high'
    if (avgLength > 100) return 'medium'
    return 'low'
  }

  detectLanguage(messages) {
    const arabicRegex = /[\u0600-\u06FF]/
    const englishRegex = /[a-zA-Z]/
    
    let arabicCount = 0
    let englishCount = 0
    
    messages.forEach(m => {
      arabicCount += (m.content.match(arabicRegex) || []).length
      englishCount += (m.content.match(englishRegex) || []).length
    })
    
    return arabicCount > englishCount ? 'arabic' : 'mixed'
  }
}

// Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙƒÙŠÙ Ø§Ù„Ø°ÙƒÙŠ
class AdaptiveResponse {
  constructor() {
    this.strategies = {
      expert: {
        temperature: 0.2,
        maxTokens: 4096,
        systemPrompt: `Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù…ØªØ®ØµØµ. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¹Ù…ÙŠÙ‚Ø© ÙˆØªÙØµÙŠÙ„ÙŠØ© Ù…Ø¹ Ù…Ø±Ø§Ø¬Ø¹ ÙˆÙ…ØµØ§Ø¯Ø±.`
      },
      teacher: {
        temperature: 0.4,
        maxTokens: 3072,
        systemPrompt: `Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ù…Ø§Ù‡Ø±. Ø§Ø´Ø±Ø­ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© ÙˆØ§Ø¶Ø­Ø©.`
      },
      creative: {
        temperature: 0.8,
        maxTokens: 2048,
        systemPrompt: `Ø£Ù†Øª Ù…Ø¨Ø¯Ø¹ ÙˆÙ…Ø¨ØªÙƒØ±. ÙÙƒØ± Ø®Ø§Ø±Ø¬ Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚ ÙˆÙ‚Ø¯Ù… Ø£ÙÙƒØ§Ø± Ø¬Ø¯ÙŠØ¯Ø©.`
      },
      analytical: {
        temperature: 0.3,
        maxTokens: 3584,
        systemPrompt: `Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø®Ø¨ÙŠØ±. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„ Ù…Ù†Ø·Ù‚ÙŠ Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø­ØµØ§Ø¦ÙŠØ§Øª.`
      }
    }
  }

  selectStrategy(userProfile, queryType) {
    const mapping = {
      technical: 'expert',
      creative: 'creative',
      analytical: 'analytical',
      conversational: 'teacher'
    }

    return this.strategies[mapping[userProfile.dominantStyle] || 'teacher']
  }
}

// Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
class AdvancedReasoning {
  constructor() {
    this.reasoningTypes = {
      deductive: 'Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ù† Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ø®Ø§Øµ',
      inductive: 'Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ù† Ø§Ù„Ø®Ø§Øµ Ù„Ù„Ø¹Ø§Ù…', 
      abductive: 'Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ ØªÙØ³ÙŠØ±',
      causal: 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬',
      analogical: 'Ø§Ù„Ù‚ÙŠØ§Ø³ ÙˆØ§Ù„ØªØ´Ø¨ÙŠÙ‡'
    }
  }

  async analyzeReasoningNeeded(query) {
    const analysis = await generateObject({
      model: deepseek('deepseek-chat'),
      schema: z.object({
        primaryReasoning: z.enum(['deductive', 'inductive', 'abductive', 'causal', 'analogical']),
        secondaryReasoning: z.array(z.enum(['deductive', 'inductive', 'abductive', 'causal', 'analogical'])),
        complexityLevel: z.enum(['basic', 'intermediate', 'advanced', 'expert']),
        requiredSteps: z.array(z.string()),
        potentialBiases: z.array(z.string())
      }),
      prompt: `Ø­Ù„Ù„ Ù†ÙˆØ¹ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰: "${query}"

      Ø­Ø¯Ø¯:
      1. Ù†ÙˆØ¹ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
      2. Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
      3. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
      4. Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
      5. Ø§Ù„ØªØ­ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§`
    })

    return analysis.object
  }

  generateReasoningPrompt(analysis) {
    return `
ğŸ§  **Ù†ÙˆØ¹ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:** ${this.reasoningTypes[analysis.primaryReasoning]}

ğŸ“‹ **Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:**
${analysis.requiredSteps.map((step, i) => `${i + 1}. ${step}`).join('\n')}

âš ï¸ **ØªØ¬Ù†Ø¨ Ù‡Ø°Ù‡ Ø§Ù„ØªØ­ÙŠØ²Ø§Øª:** ${analysis.potentialBiases.join(', ')}

ğŸ¯ **Ø§Ù„Ù…Ø³ØªÙˆÙ‰:** ${analysis.complexityLevel}

**ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªÙÙƒÙŠØ±:**
- ÙÙƒØ± Ø¨Ø´ÙƒÙ„ Ù…Ù†Ù‡Ø¬ÙŠ ÙˆÙˆØ§Ø¶Ø­
- Ø§Ø¹Ø±Ø¶ Ù…Ù†Ø·Ù‚ ØªÙÙƒÙŠØ±Ùƒ
- ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª
- Ø§Ù†ØªØ¨Ù‡ Ù„Ù„ØªØ­ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©`
  }
}

// Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©
class QualityAssurance {
  constructor() {
    this.checks = {
      accuracy: 'Ø¯Ù‚Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª',
      completeness: 'Ø´Ù…ÙˆÙ„ÙŠØ© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©',
      clarity: 'ÙˆØ¶ÙˆØ­ Ø§Ù„ØªØ¹Ø¨ÙŠØ±',
      relevance: 'Ù…Ø¯Ù‰ Ø§Ù„ØµÙ„Ø© Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„',
      depth: 'Ø¹Ù…Ù‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„'
    }
  }

  async evaluateResponse(query, response) {
    const evaluation = await generateObject({
      model: deepseek('deepseek-chat'),
      schema: z.object({
        scores: z.object({
          accuracy: z.number().min(0).max(10),
          completeness: z.number().min(0).max(10),
          clarity: z.number().min(0).max(10),
          relevance: z.number().min(0).max(10),
          depth: z.number().min(0).max(10)
        }),
        overallScore: z.number().min(0).max(10),
        improvements: z.array(z.string()),
        strengths: z.array(z.string())
      }),
      prompt: `Ù‚ÙŠÙ… Ù‡Ø°Ù‡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„:

      Ø§Ù„Ø³Ø¤Ø§Ù„: "${query}"
      Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: "${response.substring(0, 1000)}..."

      Ù‚ÙŠÙ… Ù…Ù† 1-10 ÙÙŠ:
      - Ø¯Ù‚Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
      - Ø´Ù…ÙˆÙ„ÙŠØ© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©  
      - ÙˆØ¶ÙˆØ­ Ø§Ù„ØªØ¹Ø¨ÙŠØ±
      - Ù…Ø¯Ù‰ Ø§Ù„ØµÙ„Ø© Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„
      - Ø¹Ù…Ù‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„

      ÙˆØ§Ù‚ØªØ±Ø­ ØªØ­Ø³ÙŠÙ†Ø§Øª ÙˆÙ†Ù‚Ø§Ø· Ù‚ÙˆØ©.`
    })

    return evaluation.object
  }
}

// Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø§Ù„Ù…Ø­Ø³Ù†
export async function POST(req: Request) {
  try {
    const { messages } = await req.json()
    const lastMessage = messages[messages.length - 1]?.content

    // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
    const memory = new ConversationMemory()
    const adaptive = new AdaptiveResponse()
    const reasoning = new AdvancedReasoning()
    const quality = new QualityAssurance()

    // ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ù„Ø³ÙŠØ§Ù‚
    const userProfile = memory.analyzeUser(messages)
    const reasoningAnalysis = await reasoning.analyzeReasoningNeeded(lastMessage)
    const strategy = adaptive.selectStrategy(userProfile, reasoningAnalysis.primaryReasoning)

    // Ø¥Ù†Ø´Ø§Ø¡ prompt Ù…ØªÙ‚Ø¯Ù…
    const enhancedSystemPrompt = `
${strategy.systemPrompt}

ğŸ¯ **Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙŠØ§Ù‚:**
- Ù†Ù…Ø· Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: ${userProfile.dominantStyle}
- Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯: ${userProfile.complexity}
- Ù†ÙˆØ¹ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: ${reasoningAnalysis.primaryReasoning}

${reasoning.generateReasoningPrompt(reasoningAnalysis)}

ğŸ”§ **Ù‚Ø¯Ø±Ø§ØªÙƒ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©:**
- ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø²ÙˆØ§ÙŠØ§
- ØªÙÙƒÙŠØ± Ù†Ù‚Ø¯ÙŠ Ù…Ù†Ù‡Ø¬ÙŠ
- Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø£Ø¯Ù„Ø©
- ØªÙƒÙŠÙ Ù…Ø¹ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª

ğŸ’¡ **Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:**
1. Ø§ÙÙ‡Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø¹Ù…Ù‚
2. Ø­Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
3. Ø·Ø¨Ù‚ Ù†ÙˆØ¹ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
4. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø© ÙˆÙ…Ù†Ø·Ù‚ÙŠØ©
5. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©

âš¡ **Ø§Ù„Ù‡Ø¯Ù:** ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© ØªÙ†Ø§Ø³Ø¨ Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø¯Ù‚Ø©.`

    // Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
    const result = streamText({
      model: deepseek('deepseek-chat'),
      messages: [
        ...messages.slice(0, -1),
        {
          role: 'user',
          content: `${lastMessage}

          [Ø³ÙŠØ§Ù‚ Ø¥Ø¶Ø§ÙÙŠ: Ù†Ù…Ø· Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… = ${userProfile.dominantStyle}, Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ = ${userProfile.complexity}]`
        }
      ],
      system: enhancedSystemPrompt,
      temperature: strategy.temperature,
      maxTokens: strategy.maxTokens,
      
      // Ù…Ø¹Ø§ÙŠÙŠØ± Ø¬ÙˆØ¯Ø© Ù…ØªÙ‚Ø¯Ù…Ø©
      frequencyPenalty: 0.1, // ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø±
      presencePenalty: 0.1,   // ØªØ´Ø¬ÙŠØ¹ Ø§Ù„ØªÙ†ÙˆØ¹
      
      // Ø¥Ø¶Ø§ÙØ© Ø£Ø¯ÙˆØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
      tools: {
        deepAnalysis: {
          description: 'ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ ØªØ·Ø¨ÙŠÙ‚ Ù†ÙˆØ¹ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨',
          parameters: z.object({
            query: z.string(),
            reasoningType: z.enum(['deductive', 'inductive', 'abductive', 'causal', 'analogical'])
          }),
          execute: async ({ query, reasoningType }) => {
            // ØªØ·Ø¨ÙŠÙ‚ Ù†ÙˆØ¹ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ø­Ø¯Ø¯
            const analysis = await generateObject({
              model: deepseek('deepseek-chat'),
              schema: z.object({
                keyPoints: z.array(z.string()),
                reasoning: z.array(z.string()),
                conclusions: z.array(z.string()),
                confidence: z.number().min(0).max(1)
              }),
              prompt: `Ø·Ø¨Ù‚ Ø§Ù„ØªÙÙƒÙŠØ± ${reasoningType} Ø¹Ù„Ù‰: "${query}"
              
              Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù…Ø¹:
              1. Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
              2. Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªÙÙƒÙŠØ±
              3. Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª
              4. 4. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©`
            })
            
            return analysis.object
          }
        },

        qualityCheck: {
          description: 'ÙØ­Øµ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙˆØªØ­Ø³ÙŠÙ†Ù‡Ø§',
          parameters: z.object({
            response: z.string(),
            originalQuery: z.string()
          }),
          execute: async ({ response, originalQuery }) => {
            const evaluation = await quality.evaluateResponse(originalQuery, response)
            
            return {
              evaluation,
              timestamp: new Date().toISOString()
            }
          }
        }
      },

      // Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡
      onFinish: async (result) => {
        console.log(`âœ… Response generated: ${result.text?.length || 0} chars`)
        console.log(`ğŸ¯ User profile: ${JSON.stringify(userProfile)}`)
        console.log(`ğŸ§  Reasoning used: ${reasoningAnalysis.primaryReasoning}`)
      }
    })

    return result.toDataStreamResponse()

  } catch (error) {
    console.error('âŒ Enhanced Model Error:', error)
    
    return new Response(
      JSON.stringify({ 
        error: 'Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù†. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',
        type: 'enhanced_model_error',
        timestamp: new Date().toISOString()
      }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' },
      }
    )
  }
}

// ØªØµØ¯ÙŠØ± Ø§Ù„ÙØ¦Ø§Øª Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
export { ConversationMemory, AdaptiveResponse, AdvancedReasoning, QualityAssurance }

